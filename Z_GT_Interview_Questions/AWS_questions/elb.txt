ELB stands for Elastic Load balancing. ELB automatically distributes the incoming application traffic or network traffic across multiple targets like EC2, containers, IP addresses.


********1. Diff b/w three load balancers
(((((- Classic load balancers vs Application load balancers)))))
The Application Load Balancer operates at Layer 7 of the OSI model, the network load balancer distributes traffic based on Layer 
However, the classic load balancer works at both Layer 4  

The Classic Load Balancer is a connection-based balancer where requests are forwarded by the load balancer without “looking into” any of these requests. 
They just get forwarded to the backend section.
Application Load Balancer enables content-based routing and allows requests to be routed to different applications behind a single load balance. 
While the Classic Load Balancer doesn’t do that, a single ELB can host single application. ALB isn’t an improved Classic Load balancer. It’s made on a completely new platform. 
As with Classic Load Balancer, ALB is a fully-managed, scalable, and highly available load balancing platform.
Thanks to the path-based routing feature, you can add up to 10 differrent applications behind a single ALB. 
In addition, ALB provides native support for microservices and container-based architectures. 
With Classic Load Balancer, you could only use one port at a time, while ALB instances allow you to register with multiple ports. 
To support new functionalities added inside the ALB, a few new resource types were added, including target groups, targets, and rules.


(((((- Application load balancers  vs Network load balancers)))))
The first difference is that the Application Load Balancer (as the name implies) works at the Application Layer (Layer 7 of the OSI model). 
The network load balancer works at layers 3 & 4 (network and transport layers). 
The network load balancer just forward requests whereas the application load balancer examines the contents of the HTTP request header to determine where to route the request. 
So, the application load balancer is performing content based routing.

The other difference between the two is important because network load balancing cannot assure availability of the application. This is because it bases its decisions solely on network and TCP-layer variables and has no awareness of the application at all. Generally a network load balancer will determine “availability” based on the ability of a server to respond to ICMP ping, or to correctly complete the three-way TCP handshake. An application load balancer goes much deeper, and is capable of determining availability based on not only a successful HTTP GET of a particular page but also the verification that the content is as was expected based on the input parameters.



- Gateway load balancers

*******What is an auto-scaling and what are the components?
Answer: Auto scaling allows you to automatically scale-up and scale-down the number of
instances depending on the CPU utilization or memory utilization. There are 2 components in
Auto scaling, they are Auto-scaling groups and Launch Configuration.

*******2. how autoscaling works
- Auto scaling, also referred to as autoscaling, auto-scaling, and sometimes automatic scaling, is a cloud computing technique for dynamically allocating computational resources. Depending on the load to a server farm or pool, the number of servers that are active will typically vary automatically as user needs fluctuate.

- Auto scaling and load balancing are related because an application typically scales based on load balancing serving capacity. In other words, the serving capacity of the load balancer is one of several metrics (including cloud monitoring metrics and CPU utilization) that shapes the auto scaling policy.

(or)

Amazon EC2 Auto Scaling helps you maintain application availability and allows you to automatically add or remove EC2 instances according to conditions you define. 
You can use the fleet management features of EC2 Auto Scaling to maintain the health and availability of your fleet.
You can also use the dynamic and predictive scaling features of EC2 Auto Scaling to add or remove EC2 instances. 
Dynamic scaling responds to changing demand and predictive scaling automatically schedules the right number of EC2 instances based on predicted demand.
Dynamic scaling and predictive scaling can be used together to scale faster.


*******3. Autoscaling types
When you scale horizontally, you are scaling out or in, which refers to the number of provisioned resources. When you scale vertically, it’s often called scaling up or down, which refers to the power and capacity of an individual resource.

Vertical 
Horizontal(Instance Increases automatically)

Horizontal scaling refers to provisioning additional servers to meet your needs, often splitting workloads between servers to limit the number of requests any individual server is getting. Horizontal scaling in cloud computing means adding additional instances instead of moving to a larger instance size.

Vertical scaling refers to adding more or faster CPUs, memory, or I/O resources to an existing server, or replacing one server with a more powerful server. In a data center, administrators traditionally achieved vertical scaling by purchasing a new, more powerful server and discarding or repurposing the old one. Today’s cloud architects can accomplish AWS vertical scaling and Microsoft Azure vertical scaling by changing instance sizes. AWS and Azure cloud services have many different instance sizes, so vertical scaling in cloud computing is possible for everything from EC2 instances to RDS databases.


********4. What Metrics have you used in your project
Cpu utilisation , Memory utilisation


*******5. AMI change --how to bring that change in autoscaling
1: Create your new AMI. The easiest way I have found to do this is actually via the EC2 console. ...
2: Test your AMI. ...
3: Update the launch configuration to use the AMI. ...
4: Update the Auto Scaling group

Identify the current LC used for the ASG.
Create a copy of the LC with an updated AMI.
Navigate to AWS Console –> Services –> EC2 –> Auto Scaling –> Launch Configurations.
Select a LC –> Copy launch configuration.
Click Edit AMI.
Click Create launch configuration.
Edit the ASG and select the new LC.



**********6. Launch template vs Launch configuration
A launch template is similar to a launch configuration, in that it specifies instance configuration information. ... 
For example, you cannot create an Auto Scaling group that launches both Spot and On-Demand Instances or that specifies multiple instance types or multiple launch templates.

Launch templates (LTs) are newer than launch configurations (LCs) and provide more options to work with. Thus, the AWS documentation recommends use of launch templates (LTs) over launch configuration (LCs):
We recommend that you create Auto Scaling groups from launch templates to ensure that you're getting the latest features from Amazon EC2.
One of the practical key differences between LT and LC is the fact that LC is immutable. Once you define it, you can't edit it. Only a replacement is an option. However, a single LT can have multiple versions:
Defining a launch template instead of a launch configuration allows you to have multiple versions of a template. With versioning, you can create a subset of the full set of parameters and then reuse it to create other templates or template versions.
Also LTs provide more EC2 options for you to configure, for example, dedicated hosting can be set only using a LT. Similarly, ability to use T2 unlimited burst credit option is only available in a LT.








